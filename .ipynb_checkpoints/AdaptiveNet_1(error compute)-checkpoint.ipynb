{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "420e79df-9714-4564-9870-17357b0d962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import os\n",
    "from matplotlib import rcParams\n",
    "from ForceMapping import forceMapping as fm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.set_printoptions(suppress=True)\n",
    "from itertools import product\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1471d9-5277-4756-8df2-9cf02538db43",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31ee33d0-8980-491b-8fc3-dd322a8277f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "period = 140"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88045f19-261f-461d-b58e-a70d1c56c021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep all limbs has same amount of abnormal samples\n",
    "data_normal = np.loadtxt('data_for_train.csv', delimiter=',')\n",
    "RF_ab = np.load('RF_limb.npy')\n",
    "LF_ab = np.load('LF_limb.npy')\n",
    "LH_ab = np.load('LH_limb.npy')\n",
    "RH_ab = np.load('RH_limb.npy')[period*3:,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f086bcd7-16b4-4033-aedb-a6ea9cb86b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4200"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RH_ab.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "598b64be-b4e8-4abe-a7a1-f6715f4c114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_for_predict = np.vstack((data_normal, RF_ab, LF_ab, LH_ab, RH_ab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80c40ea-1eee-40b1-881e-c450204775ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa3ae065-5e83-4869-82b2-ed2744fae397",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a90bc-4719-49ae-9916-c2c290635da8",
   "metadata": {},
   "source": [
    "#### ESN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53901843-8fc6-4dfb-8fc5-42158c458513",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn_rf, esn_lf, esn_lh, esn_rh = load_esn_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444e1285-3c1e-47bb-98dd-bda412359a59",
   "metadata": {},
   "source": [
    "#### MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d200d714-0e73-4aac-9eec-9b8285cef22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tags = [\"RF_Z\", \"RF_Y\", \"LF_Z\", \"LF_Y\", \"LH_Z\", \"LH_Y\", \"RH_Z\", \"RH_Y\"]\n",
    "models = load_named_models(MLP, model_tags, base_path=\"./Model/\", device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f15fdf-b40b-4b02-ae41-65f842e46290",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba95c2-c136-425f-93cc-56ca5a99b241",
   "metadata": {},
   "source": [
    "#### ESN prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d04bf05a-bef9-4656-b55a-668da4db0f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESN prediction\n",
    "rf_esn_prediction = esn_rf.predict(data_for_predict[:, 16:20])\n",
    "lf_esn_prediction = esn_lf.predict(data_for_predict[:, 20:24])\n",
    "lh_esn_prediction = esn_lh.predict(data_for_predict[:, 24:28])\n",
    "rh_esn_prediction = esn_rh.predict(data_for_predict[:, 28:32])\n",
    "# retrieve leading signal for MLP prediction\n",
    "rf_leading, rf_behind = split_by_half_period(rf_esn_prediction,period,70,70)\n",
    "lf_leading, lf_behind = split_by_half_period(lf_esn_prediction,period,70,70)\n",
    "lh_leading, lh_behind = split_by_half_period(lh_esn_prediction,period,70,70)\n",
    "rh_leading, rh_behind = split_by_half_period(rh_esn_prediction,period,70,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ffac2b3c-1f3a-4b1d-b2fd-5a16f792e021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resplit to indiviual sample# select y to train as an example\n",
    "'''Z'''\n",
    "# rf\n",
    "rf_in_z = reshape_to_samples(rf_leading[:,0])\n",
    "# lf\n",
    "lf_in_z = reshape_to_samples(lf_leading[:,0])\n",
    "# lh\n",
    "lh_in_z = reshape_to_samples(lh_leading[:,0])\n",
    "# rh\n",
    "rh_in_z = reshape_to_samples(rh_leading[:,0])\n",
    "\n",
    "'''Y'''\n",
    "# rf\n",
    "rf_in_y = reshape_to_samples(rf_leading[:,1])\n",
    "# lf\n",
    "lf_in_y = reshape_to_samples(lf_leading[:,1])\n",
    "# lh\n",
    "lh_in_y = reshape_to_samples(lh_leading[:,1])\n",
    "# lh\n",
    "rh_in_y = reshape_to_samples(rh_leading[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f7cac6-be92-485b-8b80-4eb2651ae1ec",
   "metadata": {},
   "source": [
    "#### MLP prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b18cdb45-2b58-4794-bb10-ea93432bc15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf signals \n",
    "RF_Z_latter_half = np.array([predict(x, models[\"RF_Z\"]) for x in rf_in_z])\n",
    "RF_Y_latter_half = np.array([predict(x, models[\"RF_Y\"]) for x in rf_in_y])\n",
    "# lf signals \n",
    "LF_Z_latter_half = np.array([predict(x, models[\"LF_Z\"]) for x in lf_in_z])\n",
    "LF_Y_latter_half = np.array([predict(x, models[\"LF_Y\"]) for x in lf_in_y])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2c825-5223-44e6-b39a-bcd1363bf0dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edc980-3d10-4a78-ae9a-cecb7adacd55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ff29f6-1015-4f60-8b48-bd7db37d5afb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e5c474-e3c9-454a-b59d-9e96ce0b442f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dfc0f62f-42fe-4b92-8379-4a0291542874",
   "metadata": {},
   "source": [
    "#### Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab26aca5-bc61-43e6-8b0b-ee6a1885cd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size=70, hidden_size=32, output_size=70):\n",
    "        super(MLP, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "def load_named_models(model_class, model_tags, base_path=\"./\", device='cpu'):\n",
    "    \"\"\"\n",
    "    Load multiple named models (e.g., MLP_RF_Z.pth) into a dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - model_class: class definition of the model (e.g., MLP)\n",
    "    - model_tags: list of tags like [\"RF_Z\", \"RF_Y\", \"LF_Z\", \"LF_Y\"]\n",
    "    - base_path: folder where model files are located\n",
    "    - device: 'cpu' or 'cuda'\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary of loaded models, e.g., models[\"RF_Z\"] -> model\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "    for tag in model_tags:\n",
    "        model = model_class()\n",
    "        path = f\"{base_path}MLP_{tag}.pth\"\n",
    "        state_dict = torch.load(path, map_location=torch.device(device))\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.to(device)\n",
    "        model.eval()\n",
    "        models[tag] = model\n",
    "    return models\n",
    "def predict(input_array, model, scaler_X=None, scaler_Y=None):\n",
    "    model.eval()\n",
    "    x = input_array.reshape(1, -1)\n",
    "    x_tensor = torch.tensor(x, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        y_tensor = model(x_tensor)\n",
    "    y = y_tensor.cpu().numpy().squeeze()\n",
    "   \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec4d8a69-0a73-47e4-93ab-cbe16b581e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ESN:\n",
    "    def __init__(self, input_size, reservoir_size, output_size, \n",
    "                 spectral_radius=0.95, sparsity=0.1, leak_rate=0.9, seed=42):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.reservoir_size = reservoir_size\n",
    "        self.output_size = output_size\n",
    "        self.leak_rate = leak_rate\n",
    "\n",
    "        # Input weights\n",
    "        self.Win = np.random.uniform(-1, 1, (reservoir_size, input_size))\n",
    "\n",
    "        # Reservoir weights\n",
    "        W = np.random.rand(reservoir_size, reservoir_size) - 0.5\n",
    "        mask = np.random.rand(*W.shape) < sparsity\n",
    "        W *= mask  # sparsify\n",
    "        eigvals = np.max(np.abs(np.linalg.eigvals(W)))\n",
    "        self.Wres = W * (spectral_radius / eigvals)\n",
    "\n",
    "        # Output weights (trained later)\n",
    "        self.Wout = None\n",
    "\n",
    "        self.state = np.zeros((reservoir_size,))\n",
    "\n",
    "    def _update_state(self, u):\n",
    "        pre_activation = np.dot(self.Win, u) + np.dot(self.Wres, self.state)\n",
    "        new_state = np.tanh(pre_activation)\n",
    "        self.state = (1 - self.leak_rate) * self.state + self.leak_rate * new_state\n",
    "        return self.state\n",
    "\n",
    "    def fit(self, inputs, targets, washout=50, ridge_lambda=1e-6):\n",
    "        states = []\n",
    "        for u in inputs:\n",
    "            state = self._update_state(u)\n",
    "            states.append(state)\n",
    "\n",
    "        states = np.array(states)\n",
    "        states_washed = states[washout:]\n",
    "        targets_washed = targets[washout:]\n",
    "\n",
    "        # Add bias term\n",
    "        extended_states = np.hstack([states_washed, np.ones((states_washed.shape[0], 1))])\n",
    "        \n",
    "        # Ridge regression\n",
    "        self.Wout = np.dot(np.linalg.pinv(extended_states), targets_washed)\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        outputs = []\n",
    "        for u in inputs:\n",
    "            state = self._update_state(u)\n",
    "            extended_state = np.concatenate([state, [1]])  # Add bias\n",
    "            y = np.dot(extended_state, self.Wout)\n",
    "            outputs.append(y)\n",
    "        return np.array(outputs)\n",
    "        \n",
    "def load_esn_models(model_dir='./Model'):\n",
    "    model_names = ['RF', 'LF', 'LH', 'RH']\n",
    "    esn_models = {}\n",
    "\n",
    "    for name in model_names:\n",
    "        file_path = f'{model_dir}/esn_{name}.pkl'\n",
    "        with open(file_path, 'rb') as f:\n",
    "            esn_models[name] = pickle.load(f)\n",
    "\n",
    "    return esn_models['RF'], esn_models['LF'], esn_models['LH'], esn_models['RH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8941230f-827a-46b1-947c-2c24e3998500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequential_data(data, period=140):\n",
    "    \"\"\"\n",
    "    Splits sequential (n, 2) time-varying data into (n//period, period, 2) samples.\n",
    "\n",
    "    Parameters:\n",
    "    - data: np.ndarray of shape (n, 2), time-series data\n",
    "    - period: int, number of time steps per sample\n",
    "\n",
    "    Returns:\n",
    "    - np.ndarray of shape (n//period, period, 2)\n",
    "    \"\"\"\n",
    "    n = data.shape[0]\n",
    "    if n % period != 0:\n",
    "        raise ValueError(f\"Length of data ({n}) is not divisible by period ({period})\")\n",
    "\n",
    "    return data.reshape(n // period, period, 2)\n",
    "\n",
    "def split_signal_halves(data_in):\n",
    "    \"\"\"\n",
    "    Splits a 3D array into two halves along the second dimension.\n",
    "\n",
    "    Parameters:\n",
    "    - data_in: np.ndarray of shape (n_samples, time_steps, channels)\n",
    "\n",
    "    Returns:\n",
    "    - data_leading: np.ndarray of shape (n_samples, time_steps//2, channels)\n",
    "    - data_behind: np.ndarray of shape (n_samples, time_steps//2, channels)\n",
    "    \"\"\"\n",
    "    midpoint = data_in.shape[1] // 2\n",
    "    data_leading = data_in[:, :midpoint, :]\n",
    "    data_behind = data_in[:, midpoint:, :]\n",
    "    return data_leading, data_behind\n",
    "\n",
    "def split_by_half_period(data, period, front_half_period, back_half_period):\n",
    "    n = data.shape[0] // period\n",
    "    set_out1 = []\n",
    "    set_out2 = []\n",
    "\n",
    "    for i in range(n):\n",
    "        start = i * period\n",
    "        set_out1.append(data[start : start + front_half_period, :])\n",
    "        set_out2.append(data[start + period - back_half_period : start + period, :])\n",
    "\n",
    "    return np.vstack(set_out1), np.vstack(set_out2)\n",
    "def reshape_to_samples(data, sample_length=70):\n",
    "    n = len(data)\n",
    "    num_samples = n // sample_length  # Number of complete samples\n",
    "    trimmed_data = data[:num_samples * sample_length]\n",
    "    reshaped = trimmed_data.reshape((num_samples, sample_length))\n",
    "    return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbc04db-60d1-460f-bf9c-335e380ddeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nyxbot)",
   "language": "python",
   "name": "nyxbot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
